{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "# Data Cleaning\n",
    "\n",
    "Notebook for creating the cleaning process for our dataset.\n",
    "<hr>\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import amzn_reviews_cleaner_funcs as amzn\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<hr>\n",
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create spark session\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
      "|      asin| helpful|overall|          reviewText| reviewTime|    reviewerID|        reviewerName|             summary|unixReviewTime|\n",
      "+----------+--------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
      "|1384719342|  [0, 0]|    5.0|Not much to write...|02 28, 2014|A2IBPI20UZIR0U|cassandra tu \"Yea...|                good|    1393545600|\n",
      "|1384719342|[13, 14]|    5.0|The product does ...|03 16, 2013|A14VAT5EAX3D9S|                Jake|                Jake|    1363392000|\n",
      "|1384719342|  [1, 1]|    5.0|The primary job o...|08 28, 2013|A195EZSQDW3E21|Rick Bennette \"Ri...|It Does The Job Well|    1377648000|\n",
      "+----------+--------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get dataframe\n",
    "# specify s3 as sourc with s3a://\n",
    "df = spark.read.json(\"s3a://amazon-review-data/reviews_Musical_Instruments_5.json.gz\")\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<hr>\n",
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+-------+--------------------+\n",
      "|      asin|    reviewerID|overall|          reviewText|\n",
      "+----------+--------------+-------+--------------------+\n",
      "|1384719342|A2IBPI20UZIR0U|    5.0|Not much to write...|\n",
      "|1384719342|A14VAT5EAX3D9S|    5.0|The product does ...|\n",
      "|1384719342|A195EZSQDW3E21|    5.0|The primary job o...|\n",
      "+----------+--------------+-------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_text = df.select(\"asin\", \"reviewerID\", \"overall\", \"reviewText\")\n",
    "df_text.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "#### Import mlib classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, CountVectorizer, StopWordsRemover, NGram, IDF\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Tokenize docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+-------+--------------------+--------------------+\n",
      "|      asin|    reviewerID|overall|          reviewText|          raw_tokens|\n",
      "+----------+--------------+-------+--------------------+--------------------+\n",
      "|1384719342|A2IBPI20UZIR0U|    5.0|Not much to write...|[not, much, to, w...|\n",
      "|1384719342|A14VAT5EAX3D9S|    5.0|The product does ...|[the, product, do...|\n",
      "|1384719342|A195EZSQDW3E21|    5.0|The primary job o...|[the, primary, jo...|\n",
      "+----------+--------------+-------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"reviewText\", outputCol=\"raw_tokens\")\n",
    "df_raw_tokens = tokenizer.transform(df_text)\n",
    "\n",
    "df_raw_tokens.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+-------+--------------------+--------------------+--------------------+\n",
      "|      asin|    reviewerID|overall|          reviewText|          raw_tokens|              tokens|\n",
      "+----------+--------------+-------+--------------------+--------------------+--------------------+\n",
      "|1384719342|A2IBPI20UZIR0U|    5.0|Not much to write...|[not, much, to, w...|[much, write, her...|\n",
      "|1384719342|A14VAT5EAX3D9S|    5.0|The product does ...|[the, product, do...|[product, exactly...|\n",
      "|1384719342|A195EZSQDW3E21|    5.0|The primary job o...|[the, primary, jo...|[primary, job, de...|\n",
      "+----------+--------------+-------+--------------------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "remover = StopWordsRemover(inputCol=\"raw_tokens\", outputCol=\"tokens\", stopWords=stopwords.words(\"english\"))\n",
    "df_tokens = remover.transform(df_raw_tokens)\n",
    "\n",
    "df_tokens.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create TF vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+-------+--------------------+--------------------+--------------------+--------------------+\n",
      "|      asin|    reviewerID|overall|          reviewText|          raw_tokens|              tokens|          tf_vectors|\n",
      "+----------+--------------+-------+--------------------+--------------------+--------------------+--------------------+\n",
      "|1384719342|A2IBPI20UZIR0U|    5.0|Not much to write...|[not, much, to, w...|[much, write, her...|(51989,[3,4,14,18...|\n",
      "|1384719342|A14VAT5EAX3D9S|    5.0|The product does ...|[the, product, do...|[product, exactly...|(51989,[2,3,14,20...|\n",
      "|1384719342|A195EZSQDW3E21|    5.0|The primary job o...|[the, primary, jo...|[primary, job, de...|(51989,[10,13,24,...|\n",
      "+----------+--------------+-------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(inputCol=\"tokens\", outputCol=\"tf_vectors\")\n",
    "tf_model = cv.fit(df_tokens)\n",
    "df_tf = tf_model.transform(df_tokens)\n",
    "\n",
    "df_tf.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'',\n",
       " u'guitar',\n",
       " u'like',\n",
       " u'one',\n",
       " u\"it's\",\n",
       " u'use',\n",
       " u'good',\n",
       " u'great',\n",
       " u'sound',\n",
       " u'get']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = tf_model.vocabulary\n",
    "\n",
    "vocab[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create IDF vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+\n",
      "|      asin|          tf_vectors|       tfidf_vectors|\n",
      "+----------+--------------------+--------------------+\n",
      "|1384719342|(51989,[3,4,14,18...|(51989,[3,4,14,18...|\n",
      "|1384719342|(51989,[2,3,14,20...|(51989,[2,3,14,20...|\n",
      "|1384719342|(51989,[10,13,24,...|(51989,[10,13,24,...|\n",
      "+----------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idf = IDF(inputCol=\"tf_vectors\", outputCol=\"tfidf_vectors\")\n",
    "idf_model = idf.fit(df_tf)\n",
    "df_idf = idf_model.transform(df_tf)\n",
    "\n",
    "df_idf.select(\"asin\", \"tf_vectors\", \"tfidf_vectors\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map most important elements from a product's tfidf_vector to the corresponding terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_row = df_idf.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(51989, {3: 1.0, 4: 1.0, 14: 1.0, 18: 2.0, 36: 1.0, 41: 1.0, 101: 1.0, 146: 1.0, 246: 1.0, 250: 1.0, 531: 1.0, 540: 2.0, 710: 1.0, 1329: 1.0, 1352: 1.0, 1387: 1.0, 1467: 1.0, 1776: 1.0, 1781: 1.0, 1907: 1.0, 2543: 1.0, 2562: 2.0, 4627: 1.0, 11514: 1.0})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_row[\"tf_vectors\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_tf_vect = test_row[\"tf_vectors\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "row_terms = []\n",
    "for i in test_tf_vect.indices:\n",
    "    row_terms.append(vocab[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'one',\n",
       " u\"it's\",\n",
       " u'well',\n",
       " u'much',\n",
       " u'buy',\n",
       " u'work',\n",
       " u'it,',\n",
       " u'might',\n",
       " u'amazon',\n",
       " u'exactly',\n",
       " u'supposed',\n",
       " u'pop',\n",
       " u'to.',\n",
       " u'honestly',\n",
       " u'sounds.',\n",
       " u'recordings',\n",
       " u'despite',\n",
       " u'here,',\n",
       " u'write',\n",
       " u'prices',\n",
       " u'lowest',\n",
       " u'filters',\n",
       " u'crisp.',\n",
       " u'pricing,']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"Not much to write about here, but it does exactly what it's supposed to. filters out the pop sounds. now my recordings are much more crisp. it is one of the lowest prices pop filters on amazon so might as well buy it, they honestly work the same despite their pricing,\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_row[\"reviewText\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
