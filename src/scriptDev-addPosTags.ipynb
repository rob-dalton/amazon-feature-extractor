{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "# Script Development - <code>addPosTags.py</code>\n",
    "Development notebook for script to add tokens and categories to review data.\n",
    "<hr>\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyspark as ps\n",
    "from sentimentAnalysis import dataProcessing as dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create spark session\n",
    "spark = ps.sql.SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get dataframes\n",
    "# specify s3 as sourc with s3a://\n",
    "#df = spark.read.json(\"s3a://amazon-review-data/user_dedup.json.gz\")\n",
    "#df_meta = spark.read.json(\"s3a://amazon-review-data/metadata.json.gz\")\n",
    "\n",
    "# get shard\n",
    "df_raw_data = spark.read.json(\"s3a://amazon-review-data/reviews_Musical_Instruments_5.json.gz\")\n",
    "\n",
    "# subset asin, reviewText\n",
    "df_subset = df_raw_data.select(\"asin\", \"reviewText\")\n",
    "\n",
    "df_tokens = dp.add_tokens(df_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "## Development\n",
    "### Add tri-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import NGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# instantiate ngram object\n",
    "ngram = NGram(n=3, inputCol=\"rawTokens\", outputCol=\"triGrams\")\n",
    "\n",
    "# add ngrams\n",
    "df_triGrams = ngram.transform(df_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|      asin|          reviewText|           cleanText|           rawTokens|              tokens|            triGrams|\n",
      "+----------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|1384719342|Not much to write...|Not much to write...|[not, much, to, w...|[much, write, exa...|[not much to, muc...|\n",
      "|1384719342|The product does ...|The product does ...|[the, product, do...|[product, exactly...|[the product does...|\n",
      "|1384719342|The primary job o...|The primary job o...|[the, primary, jo...|[primary, job, de...|[the primary job,...|\n",
      "+----------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_triGrams.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Pos Tags\n",
    "#### row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get test row\n",
    "test_row = df_triGrams.first()\n",
    "\n",
    "type(test_row[\"triGrams\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'much', 'JJ'),\n",
       " (u'write', 'NN'),\n",
       " (u'exactly', 'RB'),\n",
       " (u\"it's\", 'VBZ'),\n",
       " (u'supposed', 'VBN'),\n",
       " (u'filters', 'NNS'),\n",
       " (u'pop', 'VBP'),\n",
       " (u'sounds', 'VBZ'),\n",
       " (u'recordings', 'NNS'),\n",
       " (u'much', 'RB'),\n",
       " (u'crisp', 'VBP'),\n",
       " (u'one', 'CD'),\n",
       " (u'lowest', 'JJS'),\n",
       " (u'prices', 'NNS'),\n",
       " (u'pop', 'NN'),\n",
       " (u'filters', 'NNS'),\n",
       " (u'amazon', 'VBP'),\n",
       " (u'might', 'MD'),\n",
       " (u'well', 'RB'),\n",
       " (u'buy', 'VB'),\n",
       " (u'honestly', 'RB'),\n",
       " (u'work', 'NN'),\n",
       " (u'despite', 'IN'),\n",
       " (u'pricing', 'VBG')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test tiler\n",
    "nltk.pos_tag(test_row[\"tokens\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import ArrayType, StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|      asin|          reviewText|           cleanText|           rawTokens|              tokens|             posTags|\n",
      "+----------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|1384719342|Not much to write...|Not much to write...|[not, much, to, w...|[much, write, exa...|[WrappedArray(muc...|\n",
      "|1384719342|The product does ...|The product does ...|[the, product, do...|[product, exactly...|[WrappedArray(pro...|\n",
      "|1384719342|The primary job o...|The primary job o...|[the, primary, jo...|[primary, job, de...|[WrappedArray(pri...|\n",
      "+----------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create udf\n",
    "pos_udf = ps.sql.functions.udf(lambda x: nltk.pos_tag(x), ArrayType(ArrayType(StringType())))\n",
    "\n",
    "# apply udf, create new column\n",
    "df_posTag = df_tokens.withColumn(\"posTags\", pos_udf(df_tokens[\"tokens\"]))\n",
    "\n",
    "df_posTag.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(posTags=[[u'much', u'JJ'], [u'write', u'NN'], [u'exactly', u'RB'], [u\"it's\", u'VBZ'], [u'supposed', u'VBN'], [u'filters', u'NNS'], [u'pop', u'VBP'], [u'sounds', u'VBZ'], [u'recordings', u'NNS'], [u'much', u'RB'], [u'crisp', u'VBP'], [u'one', u'CD'], [u'lowest', u'JJS'], [u'prices', u'NNS'], [u'pop', u'NN'], [u'filters', u'NNS'], [u'amazon', u'VBP'], [u'might', u'MD'], [u'well', u'RB'], [u'buy', u'VB'], [u'honestly', u'RB'], [u'work', u'NN'], [u'despite', u'IN'], [u'pricing', u'VBG']])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_posTag.select(\"posTags\").first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tri Gram POS Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'not much to',\n",
       " u'much to write',\n",
       " u'to write about',\n",
       " u'write about here',\n",
       " u'about here but',\n",
       " u'here but it',\n",
       " u'but it does',\n",
       " u'it does exactly',\n",
       " u'does exactly what',\n",
       " u\"exactly what it's\"]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_row[\"triGrams\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tag_triGrams(triGrams):\n",
    "    tagged = []\n",
    "    for triGram in triGrams:\n",
    "        tagged.append(nltk.pos_tag(triGram.split()))\n",
    "    \n",
    "    return tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'not', u'much', u'to']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_row[\"triGrams\"][0].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(u'not', 'RB'), (u'much', 'JJ'), (u'to', 'TO')],\n",
       " [(u'much', 'JJ'), (u'to', 'TO'), (u'write', 'VB')],\n",
       " [(u'to', 'TO'), (u'write', 'VB'), (u'about', 'IN')],\n",
       " [(u'write', 'NN'), (u'about', 'IN'), (u'here', 'RB')],\n",
       " [(u'about', 'IN'), (u'here', 'RB'), (u'but', 'CC')],\n",
       " [(u'here', 'RB'), (u'but', 'CC'), (u'it', 'PRP')],\n",
       " [(u'but', 'CC'), (u'it', 'PRP'), (u'does', 'VBZ')],\n",
       " [(u'it', 'PRP'), (u'does', 'VBZ'), (u'exactly', 'RB')],\n",
       " [(u'does', 'VBZ'), (u'exactly', 'RB'), (u'what', 'WP')],\n",
       " [(u'exactly', 'RB'), (u'what', 'WP'), (u\"it's\", 'NN')]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_triGrams(test_row[\"triGrams\"])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|      asin|          reviewText|           cleanText|           rawTokens|              tokens|            triGrams|          triPosTags|\n",
      "+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|1384719342|Not much to write...|Not much to write...|[not, much, to, w...|[much, write, exa...|[not much to, muc...|[WrappedArray(Wra...|\n",
      "|1384719342|The product does ...|The product does ...|[the, product, do...|[product, exactly...|[the product does...|[WrappedArray(Wra...|\n",
      "|1384719342|The primary job o...|The primary job o...|[the, primary, jo...|[primary, job, de...|[the primary job,...|[WrappedArray(Wra...|\n",
      "+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create udf\n",
    "pos_triTag_udf = ps.sql.functions.udf(lambda x: tag_triGrams(x), ArrayType(ArrayType(ArrayType(StringType()))))\n",
    "\n",
    "# apply udf, create new column\n",
    "df_triPosTags = df_triGrams.withColumn(\"triPosTags\", pos_triTag_udf(df_triGrams[\"triGrams\"]))\n",
    "\n",
    "df_triPosTags.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_row = df_triPosTags.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[u'not', u'RB'], [u'much', u'JJ'], [u'to', u'TO']],\n",
       " [[u'much', u'JJ'], [u'to', u'TO'], [u'write', u'VB']],\n",
       " [[u'to', u'TO'], [u'write', u'VB'], [u'about', u'IN']],\n",
       " [[u'write', u'NN'], [u'about', u'IN'], [u'here', u'RB']],\n",
       " [[u'about', u'IN'], [u'here', u'RB'], [u'but', u'CC']],\n",
       " [[u'here', u'RB'], [u'but', u'CC'], [u'it', u'PRP']],\n",
       " [[u'but', u'CC'], [u'it', u'PRP'], [u'does', u'VBZ']],\n",
       " [[u'it', u'PRP'], [u'does', u'VBZ'], [u'exactly', u'RB']],\n",
       " [[u'does', u'VBZ'], [u'exactly', u'RB'], [u'what', u'WP']],\n",
       " [[u'exactly', u'RB'], [u'what', u'WP'], [u\"it's\", u'NN']],\n",
       " [[u'what', u'WP'], [u\"it's\", u'NN'], [u'supposed', u'VBD']],\n",
       " [[u\"it's\", u'NN'], [u'supposed', u'VBD'], [u'to', u'TO']],\n",
       " [[u'supposed', u'VBN'], [u'to', u'TO'], [u'filters', u'NNS']],\n",
       " [[u'to', u'TO'], [u'filters', u'NNS'], [u'out', u'RP']],\n",
       " [[u'filters', u'NNS'], [u'out', u'RP'], [u'the', u'DT']],\n",
       " [[u'out', u'IN'], [u'the', u'DT'], [u'pop', u'NN']],\n",
       " [[u'the', u'DT'], [u'pop', u'NN'], [u'sounds', u'NNS']],\n",
       " [[u'pop', u'NN'], [u'sounds', u'NNS'], [u'now', u'RB']],\n",
       " [[u'sounds', u'NNS'], [u'now', u'RB'], [u'my', u'PRP$']],\n",
       " [[u'now', u'RB'], [u'my', u'PRP$'], [u'recordings', u'NNS']],\n",
       " [[u'my', u'PRP$'], [u'recordings', u'NNS'], [u'are', u'VBP']],\n",
       " [[u'recordings', u'NNS'], [u'are', u'VBP'], [u'much', u'JJ']],\n",
       " [[u'are', u'VBP'], [u'much', u'RB'], [u'more', u'RBR']],\n",
       " [[u'much', u'RB'], [u'more', u'RBR'], [u'crisp', u'JJ']],\n",
       " [[u'more', u'RBR'], [u'crisp', u'NNS'], [u'it', u'PRP']],\n",
       " [[u'crisp', u'NN'], [u'it', u'PRP'], [u'is', u'VBZ']],\n",
       " [[u'it', u'PRP'], [u'is', u'VBZ'], [u'one', u'CD']],\n",
       " [[u'is', u'VBZ'], [u'one', u'CD'], [u'of', u'IN']],\n",
       " [[u'one', u'CD'], [u'of', u'IN'], [u'the', u'DT']],\n",
       " [[u'of', u'IN'], [u'the', u'DT'], [u'lowest', u'JJS']],\n",
       " [[u'the', u'DT'], [u'lowest', u'JJS'], [u'prices', u'NNS']],\n",
       " [[u'lowest', u'JJS'], [u'prices', u'NNS'], [u'pop', u'NN']],\n",
       " [[u'prices', u'NNS'], [u'pop', u'VBP'], [u'filters', u'NNS']],\n",
       " [[u'pop', u'NN'], [u'filters', u'NNS'], [u'on', u'IN']],\n",
       " [[u'filters', u'NNS'], [u'on', u'IN'], [u'amazon', u'NN']],\n",
       " [[u'on', u'IN'], [u'amazon', u'NNS'], [u'so', u'RB']],\n",
       " [[u'amazon', u'NNS'], [u'so', u'RB'], [u'might', u'MD']],\n",
       " [[u'so', u'RB'], [u'might', u'MD'], [u'as', u'IN']],\n",
       " [[u'might', u'MD'], [u'as', u'RB'], [u'well', u'RB']],\n",
       " [[u'as', u'IN'], [u'well', u'RB'], [u'buy', u'VB']],\n",
       " [[u'well', u'RB'], [u'buy', u'VB'], [u'it', u'PRP']],\n",
       " [[u'buy', u'VB'], [u'it', u'PRP'], [u'they', u'PRP']],\n",
       " [[u'it', u'PRP'], [u'they', u'PRP'], [u'honestly', u'RB']],\n",
       " [[u'they', u'PRP'], [u'honestly', u'RB'], [u'work', u'VBP']],\n",
       " [[u'honestly', u'RB'], [u'work', u'VBZ'], [u'the', u'DT']],\n",
       " [[u'work', u'NN'], [u'the', u'DT'], [u'same', u'JJ']],\n",
       " [[u'the', u'DT'], [u'same', u'JJ'], [u'despite', u'IN']],\n",
       " [[u'same', u'JJ'], [u'despite', u'IN'], [u'their', u'PRP$']],\n",
       " [[u'despite', u'IN'], [u'their', u'PRP$'], [u'pricing', u'NN']]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_row[\"triPosTags\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "def addPosTags(df_tokens):\n",
    "    # create udf\n",
    "    pos_udf = ps.sql.functions.udf(lambda x: nltk.pos_tag(x), ArrayType(ArrayType(StringType())))\n",
    "\n",
    "    # apply udf, create new column\n",
    "    df_posTag = df_tokens.withColumn(\"posTags\", pos_udf(df_tokens[\"tokens\"]))\n",
    "    df_posTag = df_posTag.withColumn(\"raw_posTags\", pos_udf(df_tokens[\"rawTokens\"]))\n",
    "    \n",
    "    return df_posTag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|      asin|          reviewText|           cleanText|           rawTokens|              tokens|             posTags|         raw_posTags|\n",
      "+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|1384719342|Not much to write...|Not much to write...|[not, much, to, w...|[much, write, exa...|[WrappedArray(muc...|[WrappedArray(not...|\n",
      "|1384719342|The product does ...|The product does ...|[the, product, do...|[product, exactly...|[WrappedArray(pro...|[WrappedArray(the...|\n",
      "|1384719342|The primary job o...|The primary job o...|[the, primary, jo...|[primary, job, de...|[WrappedArray(pri...|[WrappedArray(the...|\n",
      "+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "df_posTag = addPosTags(df_tokens)\n",
    "\n",
    "df_posTag.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "### Filter Pos Tags\n",
    "\n",
    "We are interested in nouns and adjectives. Nouns identify product features and adjectives expresses customer opinions of those features.\n",
    "\n",
    "However, we cannot use consecutive adjective/noun or noun/adjective pairs alone. Consider this phrase: *The chair was not great.* If we only extracted the noun *chair* and the adjective *great*, the resulting pair *chair great* does not accurately reflect the sentiment expressed in the sentence. The adverb *not* negates the positive connotation of *great*. This scenario illustrates one of a number of ways in which adjective/noun pair meanings are influenced by neighboring words.\n",
    "\n",
    "We need a set of POS sequences that can help identify sequences we are interested in. Thanfuklly, such a set exists (Turney, 2002), and we can use it here:\n",
    "<br><br>\n",
    "\n",
    "| Word 1       | Word 2            | Word 3        |\n",
    "|--------------|-------------------|---------------|\n",
    "| JJ           | NN/NS             | anything      |\n",
    "| RB/RBR/RBS   | JJ                | Not NN or NNS |\n",
    "| JJ           | JJ                | Not NN or NNS |\n",
    "| NN/ NNS      | JJ                | Not NN or NNS |\n",
    "| RB/ RBR/ RBS | VB/ VBN/ VBD/ VBG | anything      |\n",
    "\n",
    "<br><br>\n",
    "\n",
    "### *Citations*\n",
    "\n",
    "```\n",
    "Turney, Peter D. 2002. Thumbs Up or Thumbs\n",
    "Down? Semantic Orientation Applied to\n",
    "Unsupervised, Classification of Reviews.\n",
    "Proceedings of the 40th Annual Meeting of\n",
    "the Association for Computational\n",
    "Linguistics (ACL'02), Philadelphia,\n",
    "Pennsylvania, USA, July 8-10, 2002. pp\n",
    "417-424. NRC 44946\n",
    "\n",
    "\n",
    "Feature-based Customer Review Mining\n",
    "Jingye Wang Heng Ren\n",
    "Department of Computer Science\n",
    "Stanford University\n",
    "```\n",
    "<hr>\n",
    "### Identify Tag Sequences\n",
    "#### Sequence Regex Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tag_seqs_re = [('JJ', '^(NN|NS)', '.*'),\n",
    "               ('^(RB|RBR|RBS)', 'JJ', '^(?!(NN|NS)).*'),\n",
    "               ('JJ', 'JJ', '^(?!(NN|NS)).*'),\n",
    "               ('^(NN|NS)', 'JJ', '^(?!(NN|NS)).*'),\n",
    "               ('^(RB|RBR|RBS)', '^(VB|VBN|VBD|VBG)', '.*')\n",
    "              ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get python regex\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get test row\n",
    "test_row = df_posTag.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[u'not', u'RB'], [u'much', u'JJ'], [u'to', u'TO']],\n",
       " [[u'much', u'JJ'], [u'to', u'TO'], [u'write', u'VB']],\n",
       " [[u'to', u'TO'], [u'write', u'VB'], [u'about', u'IN']],\n",
       " [[u'write', u'NN'], [u'about', u'IN'], [u'here', u'RB']],\n",
       " [[u'about', u'IN'], [u'here', u'RB'], [u'but', u'CC']],\n",
       " [[u'here', u'RB'], [u'but', u'CC'], [u'it', u'PRP']],\n",
       " [[u'but', u'CC'], [u'it', u'PRP'], [u'does', u'VBZ']],\n",
       " [[u'it', u'PRP'], [u'does', u'VBZ'], [u'exactly', u'RB']],\n",
       " [[u'does', u'VBZ'], [u'exactly', u'RB'], [u'what', u'WP']],\n",
       " [[u'exactly', u'RB'], [u'what', u'WP'], [u\"it's\", u'NN']]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check triGram tags- want tagged raw tokens (stopwords not removed)\n",
    "test_row[\"triPosTags\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to check if a tagged triGram matches a single sequence\n",
    "def is_match(triPosTag, seq):\n",
    "    # iterate over tags in triPosTag\n",
    "    for i,el in enumerate(triPosTag):\n",
    "        print(el[1]+\" match \"+seq[i])\n",
    "        # return False if tag does not match sequence\n",
    "        if not re.match(el[1], seq[i]):\n",
    "            return False\n",
    "        \n",
    "    # returns true if no mismatches found\n",
    "    return True\n",
    "\n",
    "\n",
    "def match_pos_seq(taggedTriGram):\n",
    "    for el in taggedTriGram:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get test tag\n",
    "test_triPosTag = test_row[\"triPosTags\"][0]\n",
    "\n",
    "# create test match tag\n",
    "test_triPosTag_match = [[\"a\", \"NN\"], [\"b\", \"JJ\"], [\"c\", \"RR\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('^(NN|NS)', 'JJ', '^(?!(NN|NS)).*')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test regex match works\n",
    "tag_seqs_re[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match at 0x12147f558>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.match(tag_seqs_re[3][0], \"NN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN match ^(NN|NS)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('^(NN|NS)', 'JJ', '^(?!(NN|NS)).*')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test is_match()\n",
    "\n",
    "is_match(test_triPosTag_match, tag_seqs_re[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<hr>\n",
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_obj_only.write.json(\"s3a://amazon-review-data/review-data\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
